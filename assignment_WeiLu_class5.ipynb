{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3.6 (tensorflow)","language":"python","name":"rga"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"assignment_WeiLu_class5.ipynb","provenance":[{"file_id":"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class5.ipynb","timestamp":1568513543366}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2v5ICihesUN8","colab_type":"text"},"source":["# T81-558: Applications of Deep Neural Networks\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n","\n","**Module 5 Assignment: K-Fold Cross-Validation**\n","\n","**Student Name: Wei Lu**"]},{"cell_type":"markdown","metadata":{"id":"iVL0BdAtsUN9","colab_type":"text"},"source":["# Assignment Instructions\n","\n","For this assignment you will use the **reg-33-data.csv** dataset.  This is a dataset that I generated specifically for this semester.  You can find the CSV file on my data site, at this location: [reg-33-data.csv](https://data.heatonresearch.com/data/t81-558/datasets/reg-33-data.csv).\n","\n","You will train 5 neural networks, one for each fold of a 5-fold cross validation and return the out of sample predictions.  You will submit these predictions to the **submit** function.  See [Assignment #1](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class1.ipynb) for details on how to submit an assignment or check that one was submitted.\n","\n","Complete the following tasks:\n","\n","* Normalize all numerics to zscores and all text/categoricals to dummies.  Do not normalize the *target*.\n","* Your target (y) is the field named *target*.\n","* If you find any missing values (NA's), replace them with the median values for that column.\n","* Use a 5-fold cross validation and return out of sample predictions.  Your RMSE will not be as good as assignment #4, but this is because #4 was overfit.\n","* Your submission should contain the id (column name *id*), your prediction (column name *pred\"), the expected value (from the **reg-33-data.csv** dataset, named *y*, and the absolute value of the difference between the expected and predicted (column name *diff*).\n","* You might get warnings about the means of your columns differing from mine.  Do not worry about small differences. My RMSE was around 9,000. There is a large range in y, so the RMSE will be higher on this data set.\n","* Your submitted dataframe will have these columns: id, y, pred, diff.\n"]},{"cell_type":"markdown","metadata":{"id":"NTHmzLGEsUN-","colab_type":"text"},"source":["# Assignment Submit Function\n","\n","You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n","\n","**It is unlikely that should need to modify this function.**"]},{"cell_type":"code","metadata":{"id":"66qgILecsUOB","colab_type":"code","colab":{}},"source":["import base64\n","import os\n","import numpy as np\n","import pandas as pd\n","import requests\n","\n","# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n","# submission counts.  The paramaters are as follows:\n","# data - Pandas dataframe output.\n","# key - Your student key that was emailed to you.\n","# no - The assignment class number, should be 1 through 1.\n","# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n","# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n","def submit(data,key,no,source_file=None):\n","    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n","    if source_file is None: source_file = __file__\n","    suffix = '_class{}'.format(no)\n","    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n","    with open(source_file, \"rb\") as image_file:\n","        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n","    ext = os.path.splitext(source_file)[-1].lower()\n","    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n","    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n","        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n","        'assignment': no, 'ext':ext, 'py':encoded_python})\n","    if r.status_code == 200:\n","        print(\"Success: {}\".format(r.text))\n","    else: print(\"Failure: {}\".format(r.text))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yh2QNsxhsUOG","colab_type":"text"},"source":["# Google CoLab Instructions\n","\n","If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process.  Running the following code will map your GDrive to /content/drive."]},{"cell_type":"code","metadata":{"id":"KHOcNpyOsUOH","colab_type":"code","outputId":"e4ae5d7e-78dc-4704-917b-fad329b0c1c1","executionInfo":{"status":"ok","timestamp":1568576457414,"user_tz":-480,"elapsed":42163,"user":{"displayName":"陆韡","photoUrl":"","userId":"00756817164624838101"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jrjgvl8nsUOK","colab_type":"code","colab":{}},"source":["!ls /content/drive/My\\ Drive/Colab\\ Notebooks"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"Q88vxZdysUOM","colab_type":"text"},"source":["# Assignment #5 Sample Code\n","\n","The following code provides a starting point for this assignment."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"qdwHtw1PsUON","colab_type":"code","outputId":"43640cc5-57a8-47b6-8e4b-32213096ee6f","executionInfo":{"status":"error","timestamp":1570373980252,"user_tz":-480,"elapsed":13526,"user":{"displayName":"陆韡","photoUrl":"","userId":"00756817164624838101"}},"colab":{"base_uri":"https://localhost:8080/","height":474}},"source":["# Below is just a suggestion of how to begin.  \n","\n","import os\n","import pandas as pd\n","from scipy.stats import zscore\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","import pandas as pd\n","import io\n","import requests\n","import numpy as np\n","from sklearn import metrics\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from scipy.stats import zscore\n","\n","key = \"nFpEY2LlkO1YtRFzGfAdnaL2S1FiaWjD7MPdWB8B\"  # This is an example key and will not work.\n","file='/content/drive/My Drive/Colab Notebooks/assignment_WeiLu_class5.ipynb'\n","\n","# Begin assignment\n","df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/reg-33-data.csv\")\n","\n","# Encode the feature vector\n","ids = df['id']\n","df.drop('id',1,inplace=True)\n","\n","\n","# Continue here\n","\n","# Normalize all numerics to zscores and all text/categoricals to dummies. Do not normalize the target. \n","dict = df.dtypes.to_dict()\n","\n","for i in df.columns.drop('target'):\n","    if dict[i] == 'O':                   # Object\n","        df = pd.concat([df, pd.get_dummies(df[i], prefix=i)], axis=1)\n","    \n","    else:                                # numbers\n","        while pd.isnull(df[i]).sum()!=0: # Dealing with missing values\n","            med = df[i].median()\n","            df[i] = df[i].fillna(med)\n","        df[i] = zscore(df[i])\n","\n","    df.drop(i, 1, inplace=True)\n","\n","\n","x_columns = df.columns.drop('target')\n","x = df[x_columns].values\n","y = df['target'].values\n","\n","\n","# 5-fold cross validation\n","kf = KFold(5, shuffle=True, random_state=42) # Use for KFold classification\n","    \n","oos_y = []\n","oos_pred = []\n","\n","fold = 0\n","for train, test in kf.split(x):\n","    fold += 1\n","        \n","    x_train = x[train]\n","    y_train = y[train]\n","    x_test = x[test]\n","    y_test = y[test]\n","    \n","    model = Sequential()\n","    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n","    model.add(Dense(10, activation='relu'))\n","    model.add(Dense(1))\n","    model.compile(loss='mean_squared_error', optimizer='adam')\n","    \n","    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,epochs=5)\n","    \n","    pred = model.predict(x_test)\n","    \n","    oos_y.append(y_test)\n","    oos_pred.append(pred)    \n","    \n","    print(oos_y)\n","\n","\n","# Build the oos prediction list and calculate the error.\n","oos_y = np.concatenate(oos_y)\n","oos_pred = np.concatenate(oos_pred)\n","score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n","print(f\"Final, out of sample score (RMSE): {score}\")    \n","    \n","oos_y = pd.DataFrame(oos_y, columns=['y'])\n","oos_pred = pd.DataFrame(oos_pred, columns=['pred'])\n","oosDF = pd.concat( [df, oos_y, oos_pred, ids],axis=1 )\n","oosDF['diff'] = oosDF['y'] - oosDF['pred']\n","\n","\n","oosDF = oosDF[['id','y','pred','diff']]\n","#submit(source_file=file,data=oosDF,key=key,no=5)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[array([ 44098.10676858, 130572.20206375,  67926.24281326, ...,\n","       107926.99693376,  83562.39196535, 106821.09066147])]\n","[array([ 44098.10676858, 130572.20206375,  67926.24281326, ...,\n","       107926.99693376,  83562.39196535, 106821.09066147]), array([104113.78271645, 108163.98583135, 141240.44006645, ...,\n","       109447.15227132,  50696.71405222, 106308.25809457])]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9aa10cfdc4b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"NR8JMZRrlRr8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}