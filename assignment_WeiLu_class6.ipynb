{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3.6 (tensorflow)","language":"python","name":"rga"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"assignment_WeiLu_class6.ipynb","provenance":[{"file_id":"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class6.ipynb","timestamp":1568734343086}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"dxpt1PaO2mgu","colab_type":"text"},"source":["# T81-558: Applications of Deep Neural Networks\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n","\n","**Module 6 Assignment: Image Processing**\n","\n","**Student Name: Wei Lu**"]},{"cell_type":"markdown","metadata":{"id":"_jZdSBbI2mgw","colab_type":"text"},"source":["# Assignment Instructions\n","\n","For this assignment you will use two images: \n","\n","* [Dog House](https://github.com/jeffheaton/t81_558_deep_learning/raw/master/photos/hickory_home.jpg)\n","* [Land Scape](https://github.com/jeffheaton/t81_558_deep_learning/raw/master/photos/landscape.jpg)\n","\n","\n","Your code should work with any image; however, these are the two that the **submit** function is expecting.  The goal is to convert both images into square-sized.  In this module we saw how to convert to a square by cropping.  This time we will convert to a square by adding space.  If an image is [landscape orientation](https://en.wikipedia.org/wiki/Page_orientation) you will need to add space at the top and bottom.  Similarly for portrait (taller than wide) you will add space at the sides.  Make sure that the image is centered between the space. \n","\n","The following diagram illustrates this.\n","\n","![Image Processing Instructions](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/image-instructions.png \"Image Processing Instructions\")\n","\n","To calculate the color to add to the space, take the average of all RGB values.  Essentially sum all the red values, green, and blue and divide by total number of pixels.  Notice how the darker landscape picture above has a darker color added to the above/below space?  This is due to this averaging.  Make sure you convert your average RGB to integer, RGB does not have fractional values.\n","\n","The submit function will check to see if your height and width match my solution.  If your height and width are non-square or do not match my dimensions, you likely have a problem with your assignment.  \n","\n","The submit function also takes three pixels and tests them.  Pixels 1 and 3 are the upper left and lower-right, these are the average color and should match my solution exactly. You might see a difference in pixel 2, which is in the center, if you center the image differently than I do.  If you want to match my solution, make sure to round to integer after any divisions. \n"]},{"cell_type":"code","metadata":{"id":"vnFMxzor8zdw","colab_type":"code","outputId":"2da22635-5a54-4fdd-93b1-3b10903bf613","executionInfo":{"status":"ok","timestamp":1568769549111,"user_tz":-480,"elapsed":25613,"user":{"displayName":"陆韡","photoUrl":"","userId":"00756817164624838101"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uPmEAfD79EbL","colab_type":"code","outputId":"cfdc5b8c-f74e-42d1-d9ab-98c0e73c3733","executionInfo":{"status":"ok","timestamp":1568769594106,"user_tz":-480,"elapsed":1204,"user":{"displayName":"陆韡","photoUrl":"","userId":"00756817164624838101"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["!ls /content/drive/My\\ Drive/Colab\\ Notebooks"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" assignment_WeiLu_class1.ipynb\n"," assignment_WeiLu_class2.ipynb\n"," assignment_WeiLu_class3.ipynb\n"," assignment_WeiLu_class4.ipynb\n"," assignment_WeiLu_class5.ipynb\n"," assignment_WeiLu_class6.ipynb\n","'“Copy of Copy of t81_558_class06_backpropagation.ipynb”的副本'\n"," “t81_558_class_01_1_overview.ipynb”的副本\n"," “t81_558_class_01_4_python_files.ipynb”的副本\n"," “t81_558_class_01_5_python_functional.ipynb”的副本\n"," “t81_558_class_02_1_python_pandas.ipynb”的副本\n"," “t81_558_class_02_2_pandas_cat.ipynb”的副本\n"," “t81_558_class_02_3_pandas_grouping.ipynb”的副本\n"," “t81_558_class_03_2_keras.ipynb”的副本\n"," “t81_558_class_04_1_feature_encode.ipynb”的副本\n"," “t81_558_class_05_2_kfold.ipynb”的副本\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tVXrIDxi2mgy","colab_type":"text"},"source":["# Assignment Submit Function\n","\n","You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n","\n","**It is unlikely that should need to modify this function.**"]},{"cell_type":"code","metadata":{"id":"ehqcdflu2mg0","colab_type":"code","colab":{}},"source":["import base64\n","import os\n","import numpy as np\n","import pandas as pd\n","import requests\n","\n","# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n","# submission counts.  The paramaters are as follows:\n","# data - Pandas dataframe output.\n","# key - Your student key that was emailed to you.\n","# no - The assignment class number, should be 1 through 1.\n","# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n","# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n","def submit(data,key,no,source_file=None):\n","    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n","    if source_file is None: source_file = __file__\n","    suffix = '_class{}'.format(no)\n","    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n","    with open(source_file, \"rb\") as image_file:\n","        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n","    ext = os.path.splitext(source_file)[-1].lower()\n","    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n","    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n","        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n","        'assignment': no, 'ext':ext, 'py':encoded_python})\n","    if r.status_code == 200:\n","        print(\"Success: {}\".format(r.text))\n","    else: print(\"Failure: {}\".format(r.text))\n","        \n","\n","# These functions are provided to build a submission dataframe from the two images that you must\n","# generate for this assignment.  It is unlikely that you would need to modify these.\n","def scan_pixel(d,img_array,img_num,pix_num,x,y):\n","    d[f'img{img_num}-p{pix_num}-rgb0'] = [img_array[y,x,0]]\n","    d[f'img{img_num}-p{pix_num}-rgb1'] = [img_array[y,x,1]]\n","    d[f'img{img_num}-p{pix_num}-rgb2'] = [img_array[y,x,2]]\n","\n","def scan_image(d,img_num,img):\n","    img_array = np.asarray(img)\n","    rows = img_array.shape[0]\n","    cols = img_array.shape[1]\n","    d[f'img{img_num}-height'] = [rows]\n","    d[f'img{img_num}-width'] = [cols]\n","    scan_pixel(d,img_array,img_num,0,0,0)\n","    scan_pixel(d,img_array,img_num,1,int(cols/2),int(rows/2))\n","    scan_pixel(d,img_array,img_num,2,cols-1,rows-1)\n","\n","def build_submit(submit_img1, submit_img2):\n","    d = {}\n","    scan_image(d,1,submit_img1)\n","    scan_image(d,2,submit_img2)\n","    return pd.DataFrame(d)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"FrrnX1SP2mg4","colab_type":"text"},"source":["# Assignment #6 Sample Code\n","\n","The following code provides a starting point for this assignment."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"_8MKfrXV2mg5","colab_type":"code","outputId":"ad04cebc-58e2-4ad9-e115-ba15c4a3f1d8","executionInfo":{"status":"ok","timestamp":1570845706388,"user_tz":-480,"elapsed":8038,"user":{"displayName":"陆韡","photoUrl":"","userId":"00756817164624838101"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1cnCtzXxKsbSDXddp7yqYCaipKi9KA0Z4"}},"source":["%matplotlib inline\n","\n","import os\n","import pandas as pd\n","import io\n","import requests\n","import numpy as np\n","from scipy.stats import zscore\n","from PIL import Image, ImageFile\n","from matplotlib.pyplot import imshow\n","import requests\n","from io import BytesIO\n","import numpy as np\n","\n","key = \"nFpEY2LlkO1YtRFzGfAdnaL2S1FiaWjD7MPdWB8B\"  # This is an example key and will not work.\n","file='/content/drive/My Drive/Colab Notebooks/assignment_WeiLu_class6.ipynb'\n","\n","\n","def fill_square_image(img):\n","    red = 0\n","    green = 0\n","    blue = 0\n","    \n","    rows, cols = img.size\n","    pixel = cols*rows\n","\n","    img_array = np.asarray(img)\n","    #avg = int(np.mean(img_array))\n","    \n","    # calculate the color adding to the space\n","    i = 0\n","    for j in img_array.flatten():\n","        \n","        if i%3 == 0:\n","            red = red+j\n","        if i%3 == 1:\n","            green = green+j\n","        if i%3 == 2:\n","            blue = blue+j\n","        i = i+1\n"," \n","    # convert image to square-sized\n","    if rows<cols:\n","        new_image = Image.new('RGB', (cols,cols), (red//pixel,green//pixel,blue//pixel))\n","        new_image.paste(img, ((cols-rows)//2,0))\n","    \n","    else:\n","        new_image = Image.new('RGB', (rows,rows), (red//pixel,green//pixel,blue//pixel))\n","        new_image.paste(img, (0,(rows-cols)//2))\n","        \n","    return new_image\n","\n","  \n","# Handle first image\n","url = \"https://github.com/jeffheaton/t81_558_deep_learning/raw/master/photos/hickory_home.jpg\"\n","response = requests.get(url)\n","img = Image.open(BytesIO(response.content))\n","img.load()\n","submit_img1 = fill_square_image(img)\n","display(submit_img1)\n","\n","# Handle second image\n","url = \"https://github.com/jeffheaton/t81_558_deep_learning/raw/master/photos/landscape.jpg\"\n","response = requests.get(url)\n","img = Image.open(BytesIO(response.content))\n","img.load()\n","submit_img2 = fill_square_image(img)\n","display(submit_img2)\n","\n","# Submit\n","#submit_df = build_submit(submit_img1, submit_img2)\n","#submit(source_file=file,data=submit_df,key=key,no=6)"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"WldYWXq59dyO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}